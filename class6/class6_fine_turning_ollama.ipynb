{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8520f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83fce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/Documents/github/MLE_in_Gen_AI-Course/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/scott/Documents/github/MLE_in_Gen_AI-Course/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "with open(\"people_data.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    tuning_examples = []\n",
    "\n",
    "    for example in data:\n",
    "        tuning_examples.append(f\"<|user|>\\n{example['prompt']}\\n<|assistant|>\\n{json.dumps(example['response'])}<|endoftext|>\")\n",
    "\n",
    "dataset = Dataset.from_dict({'text':tuning_examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fa3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\",\n",
    "    max_seq_length = 2048, \n",
    "    dtype = None, \n",
    "    load_in_4bit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model, \n",
    "    r = 64, # rank of the matrix, the smaller the rank, the less memory it will use, and the faster the training will be\n",
    "    target_modules = [\n",
    "        'q_proj', 'k_proj', 'v_proj','o_proj', 'gate_proj', 'up_proj','down_proj'\n",
    "    ], # the modules that we want to fine-tune, we're going to inject the LoRA weights into these modules.\n",
    "     # the reason we're doing this is because these modules are the ones that are doing the heavy lifting in the model.\n",
    "     # q_proj, k_proj, v_proj are the ones that are doing the key, value, query projection of the input.\n",
    "     # o_proj is the one that is doing the final projection of the output.\n",
    "     # gate_proj and up_proj are the ones that are doing the gating and the up-projection of the input.\n",
    "     # down_proj is the one that is doing the down-projection of the output.\n",
    "\n",
    "    lora_alpha = 64 * 2, # the scaling factor for the LoRA weights, 64*2 is the default value\n",
    "    lora_dropout = 0, # the dropout rate for the LoRA weights, 0 is the default value\n",
    "    bias = 'none', # the bias for the LoRA weights, 'none' is the default value\n",
    "    use_gradient_checkpointing = 'unsloth' # the gradient checkpointing for the LoRA weights, 'unsloth' is the default value\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model, \n",
    "    train_dataset = dataset, \n",
    "    tokenizer = tokenizer, \n",
    "    dataset_text_filed = 'text',\n",
    "    max_seq_length = 2048,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 2, # the batch size for the training, 2 is the default value\n",
    "        gradient_accumulation_steps = 4, # the gradient accumulation steps for the training, 4 is the default value\n",
    "        warmup_steps= 10, # the warmup steps for the training, 10 is the default value\n",
    "        max_steps = 60, # the maximum steps for the training, 60 is the default value\n",
    "        num_train_epochs = 3, # the number of training epochs, 3 is the default value\n",
    "        logging_steps= 1, # the logging steps for the training, 1 is the default value\n",
    "        output_dir = 'outputs', # the output directory for the training, 'outputs' is the default value\n",
    "        optim = 'adamw_8bit' # the optimizer for the training, 'adamw_8bit' is the default value\n",
    "    )\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': \"Mike is a 30 year old programmer. He loves hiking.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "outputs = model.generate(input_ids=inputs, max_new_tokens = 512, use_cache=True, temperature = 0.7, do_sample=True, top_p=0.9)\n",
    "\n",
    "response = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95932b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_gguf('fineturned_model', tokenizer, quantization_method='q4_k_m', maximum_memory_usage=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
