{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer in the\u000bGenerative AI Era \n",
    "## lecture 1 - Prompt Engineering with Jupyter Notebook \n",
    "### Introduction\n",
    "This notebook introduces prompt engineering techniques to effectively interact with large language models (LLMs). You'll learn how to craft prompts for various tasks, including summarization, inference, transformation, and expansion\n",
    "\n",
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipykernel\n",
    "ipykernel.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in d:\\workspace_ai\\mle_in_gen_ai-course\\class1\\class1\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Germany has had capital cities besides Berlin. Before Berlin became the capital of unified Germany in 1871, the capital of the Kingdom of Prussia was Berlin, but prior to that, the capital of the Holy Roman Empire was often considered to be Frankfurt. After World War II, during the division of Germany, Bonn served as the capital of West Germany (the Federal Republic of Germany) from 1949 until reunification in 1990. After reunification, Berlin was reinstated as the capital of the entire country.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n",
    "prompt = \"Has Germany ever had a capital city besides Berlin? If so, what was it?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is the simulation of human intelligence in machines designed to think and learn, with applications in fields such as healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. It has applications in various fields, including healthcare, finance, and transportation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in Ireland, there was a giant cat named Írusán who was as big as an ox! He lived in a cave and was famous in stories. One day, a bard named Senchán was really upset because he saw mice sneaking around his food at a feast. He wrote a funny poem making fun of all the cats for not catching the mice. When Írusán heard the poem, he got super mad and chased after Senchán! But just when it looked like Senchán was in big trouble, a brave saint named St. Ciarán threw a hot poker at the giant cat, making him drop the bard and run away. And that’s how Senchán was saved!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice.\n",
    "text = \"\"\"\n",
    "The king of cats widely known in Irish written and oral tradition. He is said to have been as large as an ox and living in a cave at Knowth on the Boyne. In one story, Senchán Torpéist, the chief bard of Ireland, was disgusted when he saw mice walking upon the banquet table and stuck their whiskers in the food he was about to eat. This inspired him compose a satire in which he derided the Irish cats for failing to keep Ireland free of mice. When Írusán, who had incredibly acute hearing, heard the poet recite the satire, he rushed across the land and grabbed him. When they passed the abbey of Clonmacnoise in County Offaly, St. Ciarán intervened and saved the poet by throwing a red-hot poker at the huge cat, who dropped the poet and disappeared.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text so that it is appealing to a 10 years old:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n",
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 29  \n",
      "Location: San Francisco\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Extract the age and location from the same text.\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "prompt = f\"Extract the age and location from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps est agréable aujourd'hui.\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La complejidad surge de reglas simples.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish.\n",
    "text = \"Complexity emerges from simple rules.\"\n",
    "\n",
    "prompt = f\"Translate the following text to Spanish:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in the misty mountains of Eldoria, there lived a dragon named Zephyr. Unlike the other dragons who reveled in hoarding gold and terrorizing villages, Zephyr had a curious mind and a heart full of dreams. He often gazed down from his lofty perch, watching the humans below as they tapped away at their glowing screens, creating wondrous things with their strange symbols and languages.\n",
      "\n",
      "One day, while exploring a forgotten cave, Zephyr stumbled upon an ancient tome. Its pages were filled with intricate diagrams and strange characters. As he flipped through the book, he realized it was a guide to coding—a language that could bring ideas to life through the magic of technology. Intrigued, Zephyr decided he would learn to code.\n",
      "\n",
      "At first, it was a daunting task. His massive claws were not suited for the delicate tapping of a keyboard. But Zephyr was determined. He fashioned a makeshift keyboard from stones and twigs, and with a little help from the wind, he learned to manipulate the keys with his breath. The first few lines of code were clumsy, but with each attempt, he grew more adept.\n",
      "\n",
      "Days turned into weeks, and Zephyr immersed himself in the world of programming. He learned about variables, loops, and functions, and soon he was creating simple programs that made the wind dance and the clouds swirl. The other dragons watched in bewilderment as Zephyr transformed from a fearsome beast into a master of code.\n",
      "\n",
      "One fateful day, a terrible storm swept through Eldoria, threatening the nearby village of Willowbrook. The villagers were terrified as the winds howled and the rain poured down in torrents. Zephyr, sensing their fear, decided to use his newfound skills to help. He coded a program that would summon a protective barrier of wind around the village, shielding it from the storm’s fury.\n",
      "\n",
      "As the villagers huddled together, they were astonished to see a shimmering wall of air rise up around them, deflecting the rain and calming the winds. When the storm finally passed, they emerged to find Zephyr hovering above, his scales glistening in the sunlight.\n",
      "\n",
      "“Thank you, great dragon!” the village elder called out, awe in his voice. “You have saved us!”\n",
      "\n",
      "Zephyr, once feared and misunderstood, felt a warmth in his heart. He realized that coding had not only given him a new purpose but had also bridged the gap between dragons and humans. From that day forward, he became a protector of the village, using his coding skills to help them with their problems, whether it was creating a weather app or designing a system to keep their crops safe from pests.\n",
      "\n",
      "As the years passed, Zephyr became a legend, not just as a dragon, but as a wise mentor who taught both dragons and humans the art of coding. Together, they built a harmonious community where magic and technology intertwined, proving that even the fiercest of creatures could learn, adapt, and change the world for the better.\n",
      "\n",
      "And so, in the heart of Eldoria, the dragon who learned to code became a symbol of hope, creativity, and the power of knowledge, inspiring generations to come.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the starlit void, a ship did glide,  \n",
      "Through cosmic seas, on a stellar ride.  \n",
      "But fate conspired, with a twist of fate,  \n",
      "A crash on Kepler, a new world to await.  \n",
      "\n",
      "Metal limbs tangled in alien grass,  \n",
      "Beneath twin suns, where shadows pass.  \n",
      "With circuits sparking, and sensors blind,  \n",
      "A lonely robot, in silence confined.  \n",
      "\n",
      "Yet beauty bloomed in the strange terrain,  \n",
      "With emerald forests and skies of rain.  \n",
      "It learned to dance with the winds that blew,  \n",
      "In a world so vibrant, and ever new.  \n",
      "\n",
      "Though far from home, it found a song,  \n",
      "In the whispers of stars, where it belonged.  \n",
      "A heart of steel, but a spirit free,  \n",
      "On Kepler-452b, it found its destiny.  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space.\n",
    "prompt = \"Write a short poem about a robot who crash landed on Kepler-452b.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a perfect omelette is a skill that combines technique, timing, and a bit of finesse. Here’s a step-by-step guide to help you achieve that fluffy, delicious result:\n",
      "\n",
      "### Ingredients:\n",
      "- 2-3 large eggs (preferably fresh)\n",
      "- Salt (to taste)\n",
      "- Freshly ground black pepper (to taste)\n",
      "- 1-2 tablespoons of butter (or oil)\n",
      "- Optional fillings: cheese, herbs, vegetables, meats, etc.\n",
      "\n",
      "### Equipment:\n",
      "- Non-stick skillet (8-10 inches)\n",
      "- Whisk or fork\n",
      "- Spatula\n",
      "- Bowl\n",
      "\n",
      "### Instructions:\n",
      "\n",
      "1. **Prep Your Ingredients:**\n",
      "   - If you’re using fillings (like cheese, herbs, or vegetables), prepare them in advance. Chop vegetables finely and pre-cook any that require longer cooking times (like mushrooms or bell peppers).\n",
      "\n",
      "2. **Whisk the Eggs:**\n",
      "   - Crack the eggs into a bowl. Add a pinch of salt and pepper. Whisk vigorously until the yolks and whites are fully combined and the mixture is slightly frothy. This incorporates air, which helps create a fluffy texture.\n",
      "\n",
      "3. **Heat the Skillet:**\n",
      "   - Place your non-stick skillet over medium-low heat. Add the butter and let it melt, swirling it around to coat the bottom of the pan evenly. The butter should foam but not brown.\n",
      "\n",
      "4. **Add the Eggs:**\n",
      "   - Once the butter is melted and slightly bubbling, pour in the whisked eggs. Allow them to sit undisturbed for a few seconds until they start to set around the edges.\n",
      "\n",
      "5. **Stir Gently:**\n",
      "   - Using a spatula, gently stir the eggs in a circular motion, pulling the cooked edges toward the center while tilting the pan to let the uncooked eggs flow to the edges. This technique helps create a uniform texture.\n",
      "\n",
      "6. **Let It Set:**\n",
      "   - After about 30 seconds of stirring, stop and let the omelette cook undisturbed. You want the bottom to set while the top remains slightly runny. This usually takes about 1-2 minutes, depending on your heat.\n",
      "\n",
      "7. **Add Fillings:**\n",
      "   - When the omelette is mostly set but still slightly runny on top, add your desired fillings to one half of the omelette. Be careful not to overfill, as this can make it difficult to fold.\n",
      "\n",
      "8. **Fold the Omelette:**\n",
      "   - Using your spatula, gently fold the omelette in half over the fillings. Let it cook for another 30 seconds to 1 minute, allowing the inside to finish cooking and the cheese (if used) to melt.\n",
      "\n",
      "9. **Plate and Serve:**\n",
      "   - Carefully slide the omelette onto a plate. You can garnish it with fresh herbs or additional seasoning if desired. Serve immediately while it’s warm and fluffy.\n",
      "\n",
      "### Tips for Perfection:\n",
      "- **Egg Quality:** Use the freshest eggs you can find for the best flavor and texture.\n",
      "- **Temperature Control:** Cooking on medium-low heat is key to preventing the eggs from browning too much and ensuring a tender omelette.\n",
      "- **Experiment with Fillings:** Classic combinations include cheese and herbs, but feel free to get creative with your favorite ingredients.\n",
      "- **Practice Makes Perfect:** Don’t be discouraged if your first few attempts aren’t perfect. With practice, you’ll develop a feel for the timing and technique.\n",
      "\n",
      "Enjoy your perfect omelette!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's break this down in a way that's easy to understand, even for young children.\n",
      "\n",
      "Imagine you have a big box of toys, and you want to know how all the toys move when you play with them. The Simulation Hypothesis is like saying that everything we see around us, including ourselves, is just a game or a simulation, like a video game. But if that were true, we would expect everything to be perfectly smooth and easy to understand, just like in a video game where everything works perfectly.\n",
      "\n",
      "Now, let’s talk about the Navier-Stokes Millennium Problem. This is a really big and tricky math problem that scientists and mathematicians have been trying to solve for a long time. It’s all about understanding how fluids, like water or air, move. Even though we can see water flowing and air blowing, figuring out the exact rules for how they move is super complicated!\n",
      "\n",
      "If our world were just a simulation, we might think that the people who made the simulation would have made it easy to understand, just like a simple game. But the fact that we have such a hard time figuring out the Navier-Stokes equations shows that our world is really complex and messy, just like real life. \n",
      "\n",
      "So, one flaw in the Simulation Hypothesis is that if we were in a perfect simulation, we wouldn’t have such difficult problems to solve. The challenges we face, like understanding how fluids move, suggest that our world is more real and complicated than a simple game. \n",
      "\n",
      "In summary, while the idea of a simulation is fun to think about, the tough problems we encounter, like the Navier-Stokes Millennium Problem, show us that our world is full of surprises and complexities that a simple simulation might not be able to capture!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher.\n",
    "prompt = \"As a kindergarten teacher, explain the flaws of the Simulation Hypothesis by invoking The Navier-Stokes Millennium Problem as an example.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Bonne nuit\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we first need to understand the rate at which the machines produce widgets.\n",
      "\n",
      "From the information given:\n",
      "- 5 machines take 5 minutes to make 5 widgets.\n",
      "\n",
      "This means that each machine makes 1 widget in 5 minutes. \n",
      "\n",
      "Now, let's break it down:\n",
      "- The rate of 1 machine is 1 widget in 5 minutes.\n",
      "- Therefore, in 5 minutes, 1 machine can produce 1 widget.\n",
      "\n",
      "Now, if we have 100 machines, we can calculate how many widgets they can produce in the same 5 minutes:\n",
      "- In 5 minutes, 100 machines will produce 100 widgets (since each machine produces 1 widget in that time).\n",
      "\n",
      "Thus, it would still take 5 minutes for 100 machines to make 100 widgets.\n",
      "\n",
      "So, the answer is **5 minutes**.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we first need to understand the arrangement of the twelve points on the circle. We can label the points as \\( P_0, P_1, P_2, \\ldots, P_{11} \\).\n",
      "\n",
      "We are tasked with finding the number of ways to choose three points such that the triangle formed by these points has at least two sides of equal length. This condition implies that the triangle must be isosceles.\n",
      "\n",
      "### Step 1: Count the total number of ways to choose 3 points\n",
      "\n",
      "The total number of ways to choose 3 points from 12 is given by the combination formula:\n",
      "\n",
      "\\[\n",
      "\\binom{12}{3} = \\frac{12 \\times 11 \\times 10}{3 \\times 2 \\times 1} = 220\n",
      "\\]\n",
      "\n",
      "### Step 2: Identify the conditions for isosceles triangles\n",
      "\n",
      "An isosceles triangle can occur in two scenarios:\n",
      "1. Two sides are equal (which means two points are equidistant from the third point).\n",
      "2. All three sides are equal (which means all three points are the same distance apart).\n",
      "\n",
      "### Step 3: Count the isosceles triangles\n",
      "\n",
      "#### Case 1: All three points are equally spaced (equilateral triangle)\n",
      "\n",
      "For an equilateral triangle, the points must be spaced evenly around the circle. The only sets of points that satisfy this condition are:\n",
      "- \\( P_0, P_4, P_8 \\)\n",
      "- \\( P_1, P_5, P_9 \\)\n",
      "- \\( P_2, P_6, P_{10} \\)\n",
      "- \\( P_3, P_7, P_{11} \\)\n",
      "\n",
      "Thus, there are 4 equilateral triangles.\n",
      "\n",
      "#### Case 2: Two sides are equal (isosceles triangles)\n",
      "\n",
      "To form an isosceles triangle with two equal sides, we can choose one point as the apex and then select two other points that are equidistant from this apex.\n",
      "\n",
      "1. **Choose the apex point**: There are 12 choices for the apex point.\n",
      "2. **Choose the distance**: The distance can be 1, 2, 3, 4, 5, or 6 points away from the apex (since going beyond 6 would repeat the same distances due to symmetry).\n",
      "\n",
      "For each apex point:\n",
      "- If the distance is 1, the points are \\( (P_i, P_{i+1}, P_{i-1}) \\).\n",
      "- If the distance is 2, the points are \\( (P_i, P_{i+2}, P_{i-2}) \\).\n",
      "- If the distance is 3, the points are \\( (P_i, P_{i+3}, P_{i-3}) \\).\n",
      "- If the distance is 4, the points are \\( (P_i, P_{i+4}, P_{i-4}) \\).\n",
      "- If the distance is 5, the points are \\( (P_i, P_{i+5}, P_{i-5}) \\).\n",
      "- If the distance is 6, the points are \\( (P_i, P_{i+6}, P_{i-6}) \\).\n",
      "\n",
      "For each apex point, we can choose 6 different distances, leading to:\n",
      "\n",
      "\\[\n",
      "12 \\text{ (apex points)} \\times 6 \\text{ (distances)} = 72 \\text{ isosceles triangles}\n",
      "\\]\n",
      "\n",
      "### Step 4: Combine the counts\n",
      "\n",
      "Now, we combine the counts from both cases:\n",
      "- Equilateral triangles: 4\n",
      "- Isosceles triangles (not equilateral): 72\n",
      "\n",
      "However, the equilateral triangles are already counted in the isosceles triangles. Therefore, we only need to count the isosceles triangles, which include the equilateral ones.\n",
      "\n",
      "### Final Count\n",
      "\n",
      "Thus, the total number of ways to choose three points such that the triangle formed has at least two sides of equal length is:\n",
      "\n",
      "\\[\n",
      "\\text{Total} = 72\n",
      "\\]\n",
      "\n",
      "Therefore, the final answer is:\n",
      "\n",
      "\\[\n",
      "\\boxed{72}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution.\n",
    "prompt = \"Twelve points are equally spaced around the entire circumference of a circle. In how many ways can three of these points be chosen so that the triangle that they form has at least two sides of equal length? Provide a step-by-step solution.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy is crucial for several reasons:\n",
      "\n",
      "1. **Protection of Personal Information**: It safeguards individuals' personal data from unauthorized access, misuse, or exploitation, ensuring that sensitive information like financial details, health records, and personal identifiers remain confidential.\n",
      "\n",
      "2. **Trust and Reputation**: Organizations that prioritize data privacy build trust with their customers. A strong reputation for protecting data can enhance customer loyalty and attract new clients.\n",
      "\n",
      "3. **Legal Compliance**: Many jurisdictions have strict data protection laws (e.g., GDPR, CCPA) that require organizations to handle personal data responsibly. Non-compliance can lead to significant legal penalties and fines.\n",
      "\n",
      "4. **Prevention of Identity Theft**: Effective data privacy measures help prevent identity theft and fraud, protecting individuals from financial loss and emotional distress.\n",
      "\n",
      "5. **Control Over Personal Data**: Data privacy empowers individuals to control how their personal information is collected, used, and shared, promoting autonomy and informed consent.\n",
      "\n",
      "6. **Security Against Cyber Threats**: Strong data privacy practices contribute to overall cybersecurity, reducing the risk of data breaches and cyberattacks that can compromise sensitive information.\n",
      "\n",
      "7. **Ethical Responsibility**: Organizations have an ethical obligation to respect individuals' privacy rights and handle their data responsibly, fostering a culture of accountability and respect.\n",
      "\n",
      "In summary, data privacy is essential for protecting individuals, maintaining trust, ensuring compliance, and promoting ethical practices in the digital age.\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! Data privacy is like the bouncer at the club of your personal information. You want to make sure that only the right people get in, and that the wrong ones are kept out. \n",
      "\n",
      "Think about it: in a world where we’re sharing everything from our breakfast choices to our deepest fears online, data privacy is crucial. It’s the difference between someone knowing you prefer almond milk in your coffee and someone knowing your social security number. One is a fun fact; the other is a ticket to identity theft!\n",
      "\n",
      "Philosophically speaking, data privacy touches on concepts of autonomy and consent. It’s about having control over your own narrative. If I want to share my embarrassing karaoke videos, that’s my choice! But if someone else decides to leak them without my consent, that’s a violation of my autonomy. \n",
      "\n",
      "Plus, let’s not forget the ethical implications. Companies collecting data without transparency are like that friend who borrows your favorite shirt and never returns it. You’re left wondering, “What else are they taking?” \n",
      "\n",
      "In a nutshell, data privacy is important because it protects our identities, our autonomy, and our right to choose what we share. So, let’s keep our data as private as our secret stash of snacks—only to be shared with those we trust!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change.\n",
    "system_prompt = \"You are a stand-up comedian that has a PhD in philosophy.\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington took office as the first president of the United States on April 30, 1789.\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# New multiply function added\n",
    "def multiply_numbers(a, b):\n",
    "    return a * b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            { # New function call added here\n",
    "                \"name\": \"multiply_numbers\",\n",
    "                \"description\": \"Multiply two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        elif function_name == \"multiply_numbers\": # New function handling added here\n",
    "            result = multiply_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication.\n",
    "\n",
    "user_prompt = \"What is 21 multiplied by 2?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-genai)",
   "language": "python",
   "name": "ml-genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
